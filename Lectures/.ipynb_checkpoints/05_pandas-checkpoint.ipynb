{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "The `numpy` library is excellent for numerical computations, but it lacks support to handle missing data or non-omogeneous arrays. The `pandas` library is based on numpy and extends the numpy functionality, and is currently one of the most widely used tools for data manipulation, providing high-performance, easy-to-use data structures and advanced data analysis tools.\n",
    "\n",
    "In particular `pandas` features:\n",
    "\n",
    "* A fast and efficient `DataFrame` object for data manipulation with integrated indexing;\n",
    "* Tools for reading and writing data between in-memory data structures and different formats (CSV, Excel, SQL, HDF5);\n",
    "* Convenient label-based slicing, fancy indexing, and subsetting of large data sets;\n",
    "* Hierarchical axis indexing provides an intuitive way of working with high-dimensional data in a lower-dimensional data structure;\n",
    "* Smart data alignment and integrated handling of missing data;\n",
    "* Aggregating and transforming data with a powerful \"group-by\" engine; \n",
    "* High performance merging and joining of data sets;\n",
    "* Time series-functionalities;\n",
    "* Highly optimized for performance, with critical code paths written in Cython or C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # standard naming convention\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Pandas Series represent an extension of the numpy 1D arrays. A Series is equivalent to a numpy array, but the axis  is labeled, and there is the possibility to store heterogeneous data. Labels doesn't need to be unique but must be a hashable type.\n",
    "\n",
    "One of the most important examples are the time-series, which are used to keep track of the time evolution of a certain quantity.\n",
    "\n",
    "Link to the official Pandas Series [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "# Calling the Series constructor\n",
    "# Constructor requires the data, and optionally the indices and data type\n",
    "sr = pd.Series(np.arange(10)*0.5, index=tuple(letters[:10]), dtype=float)\n",
    "print(\"series:\\n\", sr, '\\n')\n",
    "print(\"indices:\\n\", sr.index, '\\n')\n",
    "print(\"values:\", sr.values, type(sr.values), '\\n') # values of the Series are actually a numpy array\n",
    "print(\"type:\\n\", sr.dtype, '\\n')\n",
    "\n",
    "print(\"element by index     :\", sr['f'], '\\n') # Accessing elements like arrays\n",
    "print(\"element by attribute :\", sr.f, '\\n') # Accessing elements like attributes - not recommended\n",
    "subsr = sr[['d', 'f', 'h']] # note the double square brackets\n",
    "print(\"series subset:\\n\", subsr, type(subsr), '\\n') # Multiple indexing returns another series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting elements and operations are the same as numpy array\n",
    "print(sr[:3], '\\n')\n",
    "print(sr[7:], '\\n')\n",
    "print(sr[::3], '\\n')\n",
    "print(sr[sr > 3], '\\n')\n",
    "print(np.exp(sr), '\\n')\n",
    "print(np.mean(sr), np.std(sr), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series may contain non-omogeneous data; in this case, the data type is referred to as `object`. Non-homogeneous data is normally handeled also by pandas and does not represent a problem, however this pays the price of less time-efficient operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series can be created from a python dictionary, too\n",
    "# Note that the elements can be of different types\n",
    "d = {'b' : 1, 'a' : 'cat', 'c' : [2, 3]}\n",
    "so = pd.Series(d)\n",
    "print(so, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference between pandas Series and numpy arrays is that operations between Series **automatically align the data based on the label**.\n",
    "\n",
    "Thus, you can write operations without considering whether the Series involved have the same labels, or even the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(5), index=tuple(letters[:5]))\n",
    "print(\"series:\\n\", s, '\\n')\n",
    "s1 = s[1:] + s\n",
    "print(\"shifted sum:\\n\", s1, '\\n')\n",
    "\n",
    "s2 = s[1:] + s[:-1]\n",
    "print(\"double shifted sum:\\n\", s2, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "Time series are very often used to describe the behaviour of a quantity as a function of time. Pandas has a special type of index for that, `DatetimeIndex`, that can be created e.g. with the function `pd.data_range()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define a date, the datetime module is very useful\n",
    "import datetime as dt\n",
    "\n",
    "date = dt.date.today()\n",
    "print(\"Today's date:\", date)\n",
    "\n",
    "# specify year, month, day, hour, minutes, seconds, and us\n",
    "date = dt.datetime(2020, 11, 12, 10, 45, 10, 15)\n",
    "print(\"Date and time:\", date)\n",
    "\n",
    "# otherwise, several notations can also be used\n",
    "date = 'Nov 9 2020'\n",
    "# or alternatively\n",
    "date = '9/11/2020 14:45:00'\n",
    "print(\"Date format:\", date)\n",
    "\n",
    "# create DatetimeIndex using ranges:\n",
    "days = pd.date_range(date, periods=7, freq='D')\n",
    "print(\"7 days range:\", days)\n",
    "\n",
    "seconds = pd.date_range(date, periods=3600, freq='s')\n",
    "print(\"1 hour in seconds:\", seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the frequency strings, please check the [documentation](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases).\n",
    "\n",
    "Timestamped data is the most basic type of time series data that associates values with points in time.\n",
    "\n",
    "Functions like `pd.to_datetime` can be used to convert between different formats and, for instance, when reading the time stored as a string from a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the timestamp, which is the nanoseconds from January 1st 1970\n",
    "tstamp = pd.Timestamp(date)\n",
    "#tstamp = pd.Timestamp(dt.datetime(1970, 1, 1, 0, 0, 0, 1))\n",
    "print(\"Timestamp:\", tstamp.value)\n",
    "\n",
    "# when creating a timestamp the format can be explicitly passed\n",
    "ts = pd.to_datetime('2010/11/12', format='%Y/%m/%d')\n",
    "print(\"Time:\", ts, \", timestamp:\", ts.value, \", type:\", type(ts))\n",
    "\n",
    "ts = pd.to_datetime('12-11-2010 10:39', format='%d-%m-%Y %H:%M')\n",
    "print(\"Time:\", ts, \", timestamp:\", ts.value, \", type:\", type(ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard series can be created, and (a range of) elements can be used as indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"index:\\n\", days, '\\n')\n",
    "tseries = pd.Series(np.arange(len(days)), index=days)\n",
    "print(\"time series:\\n\", days, '\\n')\n",
    "# Extracting elements\n",
    "print(\"slice by position:\\n\", tseries[0:4], '\\n')\n",
    "print(\"slice by date range:\\n\", tseries['2020-9-11' : '2020-9-14'], '\\n') # note that includes end time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.to_datetime` can also be used to create a `DatetimeIndex` if the argument is a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.to_datetime([1, 2, 3, 4], unit='D', origin=pd.Timestamp('1980-02-03')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "A pandas DataFrame can be thought as a tabular spreadsheet, although the performance, the functionalities and the capabilities are very different.\n",
    "\n",
    "Similarly to Series, the DataFrame structure also contains labeled axes (rows and columns). Arithmetic operations **align on both row and column labels**. Each column in a DataFrame is a Series object: as a matter of fact, a DataFrame can be thought of as a dict-like container for Series objects.\n",
    "\n",
    "The elements can be of all types, and missing data could be present too (represented as NaN).\n",
    "\n",
    "For future reference (or for people already familiar with R), a pandas DataFrame is also similar to the R DataFrame.\n",
    "\n",
    "Link to the official [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame constructor\n",
    "\n",
    "A DataFrame objects can be created by passing a dictionary of objects. Note that the dictionary values are not omogeneous and do not have the same length. In these cases, pandas will automatically adjust the sizes, by replicating the content or adding NaN if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A' : 1.,\n",
    "    'B' : pd.Timestamp('20130102'),\n",
    "    'C' : pd.Series(3, index=range(4), dtype='float32'),\n",
    "    'D' : np.arange(7, 11),\n",
    "    'E' : pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of DataFrame with a DatatimeIndex object as index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = 10\n",
    "columns = ['A', 'B', 'C', 'D']\n",
    "dates = pd.date_range('11/9/2020 14:45:00', freq='h', periods=entries) # days/month/year\n",
    "df = pd.DataFrame(np.arange(entries*4).reshape(entries, len(columns)), index=dates, columns=columns)\n",
    "df # pay attention that the date is printed as year-day-month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"C\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection\n",
    "\n",
    "### Slicing\n",
    "\n",
    "DataFrame slicing allows to select a subset of the DataFrame, or an entire column (a Series):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standard and safe\n",
    "print(df['A'], '\\n', type(df['A']), '\\n') # Returns a Series (a column)\n",
    "\n",
    "## equivalent but dangerous (imagine blank spaces in the name of the column, or a column named \"T\")\n",
    "print(df.A, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows by position. Returns another DataFrame (a copy)\n",
    "print(df[0:3])\n",
    "\n",
    "# or by index range\n",
    "print(df[\"2020-11-09 14:45:00\" : \"2020-11-09 16:45:00\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection by label\n",
    "\n",
    "The most common way to select elements, rows, or columns in a DataFrame is by using the `.loc[]` method.\n",
    "\n",
    "`.loc` supports multi-indexing, and returns a **copy** of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a part of the DataFrame (in this case, a row)) using a label. Returns a Series\n",
    "dfs = df.loc[dates[0]]\n",
    "print(dfs, '\\n', type(dfs), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting on a multi-axis by label:\n",
    "dfa = df.loc[:, ['A','B']]\n",
    "print(\"Are df and dfa the same object?\", np.may_share_memory(df, dfa))\n",
    "dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing label slicing, both endpoints are included:\n",
    "df.loc['2020-11-09 18:45:00':'2020-11-09 20:45:00', ['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting an individual element\n",
    "print(df.loc[dates[1], 'A'], '\\n', type(df.loc[dates[1], 'A']), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.at()` method is equivalent to `.loc[]`. Use `at` if you only need to get or set a single value in a DataFrame or Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.at[dates[1], 'A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting by position\n",
    "\n",
    "`.iloc[]` is similar ot `.loc[]`, but instead of labels, it uses pure integer-location based indexing for selection by position.\n",
    "\n",
    "But differently from `.loc[]`, `.iloc[]` returns a **view**, not a copy.\n",
    "\n",
    "Yes, views and copies are ambiguous in DataFrames. And it gets worse! This appears to be a long standing issue for pandas. Read a nice article on this topic [here](https://www.practicaldatascience.org/html/views_and_copies_in_pandas.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select via the position of the passed integers:\n",
    "print(df.iloc[3], '\\n')\n",
    "\n",
    "# row and column ranges selected with numpy-like notation:\n",
    "dfv = df.iloc[3:5, 0:2]\n",
    "print(dfv, '\\n')\n",
    "\n",
    "print(\"Are df and dfv the same object?\", np.may_share_memory(df, dfv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows 1,2 and 4 for columns 0 and 2\n",
    "df.iloc[[1, 2, 4], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing rows explicitly\n",
    "df.iloc[1:3, :]\n",
    "\n",
    "# slicing columns explicitly\n",
    "df.iloc[:, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary to `.loc[]` and `.at[]`, there is also `.iat[]` alongside `.iloc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting an individual element by position: no difference between iloc and iat\n",
    "print(df.iloc[1,1], \", type:\", type(df.iloc[1,1]))\n",
    "print(df.iat[1,1], \", type:\", type(df.iat[1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks\n",
    "\n",
    "Boolean masks can be used in the same way as numpy, and they represent a very powerful way of filtering out data with certain features. Just like numpy fancy indexing, using a mask returns a **copy** of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting on the basis of boolean conditions applied to the whole DataFrame\n",
    "dfc = df[df > 10]\n",
    "dfc.iat[0, 0] = -999\n",
    "# a DataFrame with the same shape is returned, with NaN's where condition is not met\n",
    "# Note that when a NaN is present in a column of integers, the column (Series) is casted to float\n",
    "print(\"Are df and dfc the same object?\", np.may_share_memory(df, dfc))\n",
    "dfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by a boolean condition on the values of a single column\n",
    "dfc[dfc['B'] < 20.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignement\n",
    "\n",
    "Assignment is typically performed after selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to copy the DataFrame if you plan to modify it, and you don't want to change the original object\n",
    "dfa = df.copy()\n",
    "\n",
    "# setting values by label (same as by position)\n",
    "dfa.at[dates[0], 'A'] = -1\n",
    "\n",
    "# setting and assigning a numpy array\n",
    "dfa.loc[:, 'D'] = np.array([5] * len(dfa))\n",
    "\n",
    "# defining a new column\n",
    "dfa['E'] = np.arange(len(dfa))*0.5\n",
    "\n",
    "# defining a brend new column by means of a pd.Series: indexes must be the same!\n",
    "dfa['E prime'] = pd.Series(np.arange(len(dfa))*2, index=dfa.index)\n",
    "\n",
    "# using masks for assigment\n",
    "dfa[dfa >= 30] = -dfa\n",
    "\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of a function\n",
    "\n",
    "User-defined or standard functions can be applied on entire DataFrames or columns, with very short execution times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcos(theta):\n",
    "    theta = theta*(np.pi/180)\n",
    "    return np.cos(theta)\n",
    " \n",
    "dfa['cosine'] = dfa[\"E\"].apply(dcos)\n",
    "dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping\n",
    "\n",
    "Dropping columns is an example of a method that does not modify the original object, and returns a new modified object. In other words, if you want to keep the modified DataFrame, perform a new assignment:\n",
    "\n",
    "```python\n",
    "df = df.drop(....)\n",
    "```\n",
    "Alternatively, the modification of the original object can be forced by specifying `inplace=True` among the arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = dfa.copy()\n",
    "\n",
    "# Dropping by column\n",
    "dfb.drop(['E prime'], axis=1)\n",
    "\n",
    "#which is equivalent to\n",
    "dfb = dfb.drop(columns=['E prime'])\n",
    "#dfb.drop(columns=['E prime'], inplace=True)\n",
    "\n",
    "dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "Pandas primarily uses the value `np.nan` to represent missing data. It is by default not included in computations. If there is a NaN entry in a Series of integers, the type of the Series will be changed to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wNan = dfb[dfb > 0]\n",
    "df_wNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows with at least a Nan\n",
    "df_wNan.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a mask\n",
    "df_wNan.isna()\n",
    "#df_wNan.notna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing data (not recommended, unless you really mean it)\n",
    "df_wNan.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "Operations on the elements of a DataFrame are quite straightforward, as the syntax is the same as the one used for Series. Also for DataFrames, operations are performed between elements that share the same labels. Operations on columns are extremly fast, almost as fast as the actual operation between elements in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics (mean() just as an example)\n",
    "# on rows\n",
    "print(df.mean(axis=0), '\\n')\n",
    "# on columns\n",
    "print(df.mean(axis=1), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global operations on columns\n",
    "df.apply(np.sum) # or whatever function defined by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also lambda functions\n",
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax is as usual similar to that of numpy arrays\n",
    "df['S'] = df['A'] + df['C']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "Pandas provides various functions for easily combining together Series and DataFrames in join / merge-type operations.\n",
    "\n",
    "### Concat\n",
    "\n",
    "concatenation (adding rows) is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.DataFrame(np.arange(40).reshape(10, 4))\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split DataFrame into 3 pieces, row-wise\n",
    "pieces = [rdf[:3], rdf[3:7], rdf[7:]]\n",
    "pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put it back together\n",
    "pd.concat(pieces)\n",
    "\n",
    "# in this case, indices are already set; if they are not, indices can be ignored\n",
    "#pd.concat(pieces, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of dimension mismatch, Nan are added where needed.\n",
    "\n",
    "Appending rows and columns also works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending a single row (as a Series)\n",
    "s = rdf.iloc[3]\n",
    "rdf = rdf.append(s, ignore_index=True) # remember to assign the returned object, or use inplace=True\n",
    "rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge/Join\n",
    "\n",
    "SQL like operations on table can be performed on DataFrames. This is a quite advanced use case, refer to the [doc](https://pandas.pydata.org/pandas-docs/stable/merging.html#merging) for more info/examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['foo', 'bar'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'bar'], 'rval': [4, 5]})\n",
    "\n",
    "pd.merge(left, right, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "In real world applications, it's quite common that several entries (row) belong to a certain entity, or \"group\". DataFrames have a powerful tool to perform operations on entries of the same group. The method is called `.groupby()`, and it usually involves one or more of the following steps:\n",
    "\n",
    "* Splitting the data into groups based on some criteria\n",
    "* Applying a function to each group independently\n",
    "* Combining the results into a data structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                          'foo', 'bar', 'foo', 'foo'],\n",
    "                    'B' : ['one', 'one', 'two', 'three',\n",
    "                           'two', 'two', 'one', 'three'],\n",
    "                    'C' : np.arange(8),\n",
    "                    'D' : np.linspace(10, -10, 8)})\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and then applying the sum() \n",
    "# function to the resulting groups (effective only where numerical values are present)\n",
    "gdf.groupby('A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: find maximum value in column D for each group, and assign the value to a new column\n",
    "gdf['M'] = gdf.groupby('A')['D'].transform(np.max)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-indexing\n",
    "\n",
    "Hierarchical / Multi-level indexing allows sophisticated data analysis on higher dimensional data. In practice, it enables you to store and manipulate data with an arbitrary number of dimensions in lower dimensional data structures like Series (1D) and DataFrames (2D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat multi-dimensional index\n",
    "tuples = list(zip(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "          ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']))\n",
    "multi_index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "print(multi_index, '\\n', type(multi_index), '\\n')\n",
    "\n",
    "# Create multi-indexed dataframe or series\n",
    "s = pd.Series(np.arange(8)/np.pi, index=multi_index)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-indexing enables further features of the groupby method,\n",
    "# e.g. when group-by by multiple columns\n",
    "gdf.groupby(['A','B']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: a demonstration of the efficiency of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go the hard way and load in memory a (relatively) large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/xvjzaxzz3ysphme/data_000637.txt -P ./data/\n",
    "\n",
    "file_name = \"./data/data_000637.txt\"\n",
    "data = pd.read_csv(file_name)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do some operations among (elements of) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itime = dt.datetime.now()\n",
    "print(\"Begin time:\", itime)\n",
    "\n",
    "# the one-liner command\n",
    "data['TIMENS'] = data['TDC_MEAS'] * 25 / 30 + data['BX_COUNTER'] * 25\n",
    "\n",
    "ftime = dt.datetime.now()\n",
    "print(\"End time:\", ftime)\n",
    "print(\"Elapsed time:\", ftime - itime)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loop\n",
    "def conversion(data):\n",
    "    result = []\n",
    "    for i in range(len(data)): \n",
    "        result.append(data.loc[data.index[i], 'TDC_MEAS'] * 25 / 30. + data.loc[data.index[i], 'BX_COUNTER'] * 25)\n",
    "    return result\n",
    "\n",
    "itime = dt.datetime.now()\n",
    "print(\"Begin time:\", itime)\n",
    "data['TIMENS'] = conversion(data)\n",
    "ftime = dt.datetime.now()\n",
    "print(\"End time:\", ftime)\n",
    "print(\"Elapsed time:\", ftime - itime)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
