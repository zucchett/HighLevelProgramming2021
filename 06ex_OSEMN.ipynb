{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named \"data_int.txt\". Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named \"data_float.txt\". Use the `cat` command to print the content of the file.\n",
    "+ load the txt file of the previous point and convert it to a csv file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 \n"
     ]
    }
   ],
   "source": [
    "##1\n",
    "\n",
    "file =\"data/data_int.txt\"\n",
    "with open(file,'w') as outfile:\n",
    "    string = \"\"\n",
    "    for x in range(10):\n",
    "        string = string + str(x) + \" \"\n",
    "    outfile.write(string)\n",
    "with open(file, 'r') as outfile:\n",
    "    print(outfile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "##2\n",
    "\n",
    "file = \"data/data_float.txt\"\n",
    "mtrx = str([[0.0 for a in range(5)] for b in range(5)])\n",
    "with open(file, 'w') as outfile:\n",
    "    outfile.write(mtrx)\n",
    "    \n",
    "with open(file, mode = 'r') as f:\n",
    "     print(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-5436a4717db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmylist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-5436a4717db0>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"]\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmylist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmylist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "##3\n",
    "\n",
    "import csv \n",
    "\n",
    "file1 = \"data/data_int.txt\"\n",
    "file2 = \"data/data_float.txt\"\n",
    "\n",
    "with open(file1,'r') as in_file:\n",
    "    with open('data/data_int.csv','w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        data = in_file.read()\n",
    "        data = data.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        mylist = list(int(i) for i in data.split(','))\n",
    "        print(mylist)\n",
    "        writer.writerow(mylist)\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file containing the list of int:  \n"
     ]
    }
   ],
   "source": [
    "with open('data/data_int.csv', 'r') as csv_file:\n",
    "    print(\"csv file containing the list of int: \", csv_file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data: \n",
      " [{'ID': '2', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Clint_Thorpe5003@bulaffy.com', 'FirstNameLastName': 'Clint Thorpe', 'CreditCard': '7083-8766-0251-2345', 'CreditCardType': 'American Express'}, {'ID': '12', 'JobTitle': 'Retail Trainee', 'EmailAddress': 'Phillip_Carpenter9505@famism.biz', 'FirstNameLastName': 'Phillip Carpenter', 'CreditCard': '3657-0088-0820-5247', 'CreditCardType': 'American Express'}, {'ID': '28', 'JobTitle': 'Project Manager', 'EmailAddress': 'Russel_Graves1378@extex.org', 'FirstNameLastName': 'Russel Graves', 'CreditCard': '6718-4818-8011-6024', 'CreditCardType': 'American Express'}, {'ID': '39', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Leanne_Newton1268@typill.biz', 'FirstNameLastName': 'Leanne Newton', 'CreditCard': '5438-0816-4166-4847', 'CreditCardType': 'American Express'}, {'ID': '57', 'JobTitle': 'Budget Analyst', 'EmailAddress': 'Tony_Giles1960@iatim.tech', 'FirstNameLastName': 'Tony Giles', 'CreditCard': '8130-3425-7573-7745', 'CreditCardType': 'American Express'}, {'ID': '62', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Owen_Allcott5125@bauros.biz', 'FirstNameLastName': 'Owen Allcott', 'CreditCard': '4156-0107-7210-2630', 'CreditCardType': 'American Express'}, {'ID': '68', 'JobTitle': 'Project Manager', 'EmailAddress': 'Liam_Lynn3280@kideod.biz', 'FirstNameLastName': 'Liam Lynn', 'CreditCard': '7152-3247-6053-2233', 'CreditCardType': 'American Express'}, {'ID': '74', 'JobTitle': 'Dentist', 'EmailAddress': 'Regina_Woodcock5820@yahoo.com', 'FirstNameLastName': 'Regina Woodcock', 'CreditCard': '0208-1753-3870-8002', 'CreditCardType': 'American Express'}, {'ID': '81', 'JobTitle': 'HR Specialist', 'EmailAddress': 'Carter_Wallace9614@atink.com', 'FirstNameLastName': 'Carter Wallace', 'CreditCard': '4256-7201-6717-4322', 'CreditCardType': 'American Express'}, {'ID': '92', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Maia_Stark2797@jiman.org', 'FirstNameLastName': 'Maia Stark', 'CreditCard': '3851-1403-1734-6321', 'CreditCardType': 'American Express'}, {'ID': '97', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Ciara_Lomax982@bauros.biz', 'FirstNameLastName': 'Ciara Lomax', 'CreditCard': '3702-3440-2472-5424', 'CreditCardType': 'American Express'}, {'ID': '116', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Isabel_Ellwood1475@fuliss.net', 'FirstNameLastName': 'Isabel Ellwood', 'CreditCard': '3738-0882-0066-6683', 'CreditCardType': 'American Express'}, {'ID': '148', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Abdul_Townend2202@infotech44.tech', 'FirstNameLastName': 'Abdul Townend', 'CreditCard': '4224-1226-3557-3448', 'CreditCardType': 'American Express'}, {'ID': '150', 'JobTitle': 'Fabricator', 'EmailAddress': 'Caleb_Poulton1735@atink.com', 'FirstNameLastName': 'Caleb Poulton', 'CreditCard': '8203-6875-5225-0341', 'CreditCardType': 'American Express'}, {'ID': '151', 'JobTitle': 'Restaurant Manager', 'EmailAddress': 'Ronald_Lewis6777@deavo.com', 'FirstNameLastName': 'Ronald Lewis', 'CreditCard': '7212-0155-5014-8471', 'CreditCardType': 'American Express'}, {'ID': '154', 'JobTitle': 'Bellman', 'EmailAddress': 'Faith_Seymour3829@twace.org', 'FirstNameLastName': 'Faith Seymour', 'CreditCard': '4170-5186-6887-6558', 'CreditCardType': 'American Express'}, {'ID': '169', 'JobTitle': 'Assistant Buyer', 'EmailAddress': 'Anthony_Hancock9083@qater.org', 'FirstNameLastName': 'Anthony Hancock', 'CreditCard': '0832-3357-6010-6550', 'CreditCardType': 'American Express'}, {'ID': '176', 'JobTitle': 'Healthcare Specialist', 'EmailAddress': 'Isabella_Willson5478@nanoff.biz', 'FirstNameLastName': 'Isabella Willson', 'CreditCard': '5177-4868-4623-0384', 'CreditCardType': 'American Express'}, {'ID': '182', 'JobTitle': 'Pharmacist', 'EmailAddress': 'Stephanie_Darcy3298@bauros.biz', 'FirstNameLastName': 'Stephanie Darcy', 'CreditCard': '0264-4020-5106-5576', 'CreditCardType': 'American Express'}, {'ID': '199', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Ryan_Kennedy5565@corti.com', 'FirstNameLastName': 'Ryan Kennedy', 'CreditCard': '3166-6287-6242-7207', 'CreditCardType': 'American Express'}]\n"
     ]
    }
   ],
   "source": [
    "import json, csv\n",
    "\n",
    "data = json.load(open('data/user_data(1).json'))\n",
    "filtered = [dict for dict in data if dict['CreditCardType']=='American Express']\n",
    "print(\"Filtered data: \\n\", filtered)\n",
    "\n",
    "writer = csv.DictWriter(open('data/jsons.csv', 'w'), filtered[0].keys())\n",
    "for dict in filtered:\n",
    "    writer.writerow(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.266160</td>\n",
       "      <td>1.615970</td>\n",
       "      <td>4.581749</td>\n",
       "      <td>0.653992</td>\n",
       "      <td>4.334601</td>\n",
       "      <td>0.954373</td>\n",
       "      <td>0.285171</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>6.622624</td>\n",
       "      <td>0.615970</td>\n",
       "      <td>...</td>\n",
       "      <td>1.798479</td>\n",
       "      <td>6.098859</td>\n",
       "      <td>6.064639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.931559</td>\n",
       "      <td>1.125475</td>\n",
       "      <td>3.007605</td>\n",
       "      <td>3.201521</td>\n",
       "      <td>3.283270</td>\n",
       "      <td>1.148289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.436159</td>\n",
       "      <td>2.055158</td>\n",
       "      <td>4.421859</td>\n",
       "      <td>0.159346</td>\n",
       "      <td>3.940756</td>\n",
       "      <td>0.995403</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>0.567926</td>\n",
       "      <td>2.863636</td>\n",
       "      <td>0.514811</td>\n",
       "      <td>...</td>\n",
       "      <td>1.394280</td>\n",
       "      <td>5.512768</td>\n",
       "      <td>5.504597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.002043</td>\n",
       "      <td>1.009193</td>\n",
       "      <td>1.522983</td>\n",
       "      <td>4.021450</td>\n",
       "      <td>4.031665</td>\n",
       "      <td>1.895812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
       "class                                                                           \n",
       "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
       "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
       "\n",
       "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
       "class                                                    ...   \n",
       "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
       "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
       "\n",
       "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
       "class                                                     \n",
       "0                      1.798479                6.098859   \n",
       "1                      1.394280                5.512768   \n",
       "\n",
       "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
       "class                                                                          \n",
       "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
       "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
       "\n",
       "       spore-print-color  population   habitat  \n",
       "class                                           \n",
       "0               3.201521    3.283270  1.148289  \n",
       "1               4.021450    4.031665  1.895812  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/mushrooms_categorized.csv\")\n",
    "\n",
    "means = df.groupby([\"class\"]).agg('mean')\n",
    "\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/credit_card.dat','rb') as file:\n",
    "    while True:\n",
    "        file_content=file.readline()\n",
    "        \n",
    "        ints=[]\n",
    "        try:\n",
    "            for i in range(1,20*7,7):\n",
    "                if (i==34 or i==64 or i==94):\n",
    "                    continue\n",
    "                ints.append(int(file_content[i:i+6], 2))\n",
    "        except ValueError:\n",
    "            break\n",
    "        print(\"-\". join(str(j) for j in ints))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Optional**: load the remote file:\n",
    "\n",
    "- https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "\n",
    "with Pandas and create a scatter plot with all possible combinations of the following features:\n",
    "    \n",
    "  + features_1\n",
    "  + features_2\n",
    "  + features_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
